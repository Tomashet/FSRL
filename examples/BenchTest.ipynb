{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from SafeRLBench import config\n",
    "from SafeRLBench import Bench, BenchConfig, BestPerformance\n",
    "from SafeRLBench.algo import PolicyGradient\n",
    "from SafeRLBench.envs import LinearCar, GeneralMountainCar\n",
    "from SafeRLBench.policy import LinearPolicy, NoisyLinearPolicy\n",
    "from SafeRLBench.spaces import BoundedSpace\n",
    "from SafeRLBench import SRBConfig\n",
    "\n",
    "import logging\n",
    "    \n",
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config.logger_set_level(logging.DEBUG)\n",
    "config.logger_add_stream_handler()\n",
    "# config.logger_add_file_handler('BenchTestLog.log')\n",
    "config.monitor_set_verbosity(2)\n",
    "config.jobs_set(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# configure policy\n",
    "policy = LinearPolicy(2, 1)\n",
    "noisy_policy = NoisyLinearPolicy(2, 1, sigma=1)\n",
    "noisy_policy.parameter_space = BoundedSpace(-1, 1, (3,))\n",
    "\n",
    "# configure environments\n",
    "algs = [\n",
<<<<<<< HEAD
    "    (PolicyGradient, [{'policy': noisy_policy, 'max_it': 500, 'eps': 0.0000000001, 'estimator': 'reinforce', 'rate': 4, 'var': 0.5},\n",
    "                      {'policy': policy, 'max_it': 500, 'eps': 0.0000001, 'estimator': 'central_fd', 'var': 5}])\n",
=======
    "    (PolicyGradient, [{'policy': noisy_policy, 'max_it': 2000, 'eps': 0.0000000001, 'estimator': 'reinforce', 'rate': 4, 'var': 0.5},\n",
    "                      {'policy': policy, 'max_it': 2000, 'eps': 0.0000001, 'estimator': 'central_fd', 'var': 5}])\n",
>>>>>>> master
    "]\n",
    "\n",
    "env = [[\n",
    "    (LinearCar, {'horizon': 200})\n",
    "]]\n",
    "\n",
    "\n",
    "test_config = BenchConfig(algs, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benchmark = Bench(test_config, [BestPerformance()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5462 - 2017-02-08 14:45:46,491 - SafeRLBench.bench - DEBUG - Starting benchmarking.\n",
      "5502 - 2017-02-08 14:45:46,581 - SafeRLBench.bench - DEBUG - DISPATCH RUN:\n",
      "\n",
      "   Algorithm:   \n",
      "     PolicyGradient  \n",
      "    {  eps : 1e-10 \n",
      "       estimator :  reinforce  \n",
      "       max_it : 500 \n",
      "       policy : <SafeRLBench.policy.linear_policy.NoisyLinearPolicy object at 0x110d7db70> \n",
      "       rate : 4 \n",
      "       var : 0.5}  \n",
      "   Environment:   \n",
      "    LinearCar   { horizon : 100}  \n",
      "\n",
      "5502 - 2017-02-08 14:45:46,615 - SafeRLBench.monitor - INFO - Starting optimization of PolicyGradient...\n",
      "5503 - 2017-02-08 14:45:46,588 - SafeRLBench.bench - DEBUG - DISPATCH RUN:\n",
      "\n",
      "   Algorithm:   \n",
      "     PolicyGradient  \n",
      "    {  eps : 1e-07 \n",
      "       estimator :  central_fd  \n",
      "       max_it : 500 \n",
      "       policy : <SafeRLBench.policy.linear_policy.LinearPolicy object at 0x110d7dc88> \n",
      "       var : 5}  \n",
      "   Environment:   \n",
      "    LinearCar   { horizon : 100}  \n",
      "\n",
      "5503 - 2017-02-08 14:45:46,754 - SafeRLBench.monitor - INFO - Starting optimization of PolicyGradient...\n",
      "5503 - 2017-02-08 14:45:59,125 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 100\tTime: 12.36\t Avg: 0.124\n",
      "\tParameter: \t[ 0.14186  0.38766  0.71052]\n",
      "\tGradient: \t[-0.01524 -0.04201  0.01764]\n",
      "\n",
      "5503 - 2017-02-08 14:46:14,963 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 200\tTime: 28.19\t Avg: 0.141\n",
      "\tParameter: \t[ 0.14186  0.38766  0.71052]\n",
      "\tGradient: \t[-0.00971 -0.02702  0.01028]\n",
      "\n",
      "5503 - 2017-02-08 14:46:30,747 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 300\tTime: 43.98\t Avg: 0.147\n",
      "\tParameter: \t[ 0.14186  0.38766  0.71052]\n",
      "\tGradient: \t[-0.00712 -0.02503  0.0087 ]\n",
      "\n",
      "5502 - 2017-02-08 14:46:40,066 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 100\tTime: 53.44\t Avg: 0.534\n",
      "\tParameter: \t[-0.71629 -0.22468  0.42103]\n",
      "\tGradient: \t[ 0.00121  0.00038 -0.00071]\n",
      "\n",
      "5503 - 2017-02-08 14:46:45,457 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 400\tTime: 58.69\t Avg: 0.147\n",
      "\tParameter: \t[ 0.14186  0.38766  0.71052]\n",
      "\tGradient: \t[-0.00593 -0.02151  0.0067 ]\n",
      "\n",
      "5502 - 2017-02-08 14:46:53,806 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 200\tTime: 67.18\t Avg: 0.336\n",
      "\tParameter: \t[-0.71629 -0.22468  0.42103]\n",
      "\tGradient: \t[  1.22645e-04   3.84707e-05  -7.20904e-05]\n",
      "\n",
      "5503 - 2017-02-08 14:46:59,043 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 500\tTime: 72.28\t Avg: 0.145\n",
      "\tParameter: \t[ 0.14186  0.38766  0.71052]\n",
      "\tGradient: \t[-0.00483 -0.01879  0.0053 ]\n",
      "\n",
      "5503 - 2017-02-08 14:46:59,077 - SafeRLBench.monitor - DEBUG - Finished optimization after 500 steps with grad [-0.00483 -0.01879  0.0053 ].\n",
      "5503 - 2017-02-08 14:46:59,091 - SafeRLBench.monitor - INFO - Computing traces for PolicyGradient run...\n",
      "5502 - 2017-02-08 14:47:08,109 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 300\tTime: 81.48\t Avg: 0.272\n",
      "\tParameter: \t[-0.71629 -0.22468  0.42103]\n",
      "\tGradient: \t[  3.71445e-07   1.16513e-07  -2.18334e-07]\n",
      "\n",
      "5502 - 2017-02-08 14:47:21,618 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 400\tTime: 94.99\t Avg: 0.237\n",
      "\tParameter: \t[-0.71629 -0.22468  0.42103]\n",
      "\tGradient: \t[  1.50019e-08   4.70573e-09  -8.81809e-09]\n",
      "\n",
      "5502 - 2017-02-08 14:47:32,778 - SafeRLBench.monitor - INFO - Status for PolicyGradient on LinearCar:\n",
      "\n",
      "\tRun: 500\tTime: 106.15\t Avg: 0.212\n",
      "\tParameter: \t[-0.71629 -0.22468  0.42103]\n",
      "\tGradient: \t[  2.93785e-09   9.21530e-10  -1.72686e-09]\n",
      "\n",
      "5502 - 2017-02-08 14:47:32,883 - SafeRLBench.monitor - DEBUG - Finished optimization after 500 steps with grad [  2.93785e-09   9.21530e-10  -1.72686e-09].\n",
      "5502 - 2017-02-08 14:47:32,892 - SafeRLBench.monitor - INFO - Computing traces for PolicyGradient run...\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> master
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benchmark.measures[0].result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor = benchmark.measures[0].result[0][0].get_alg_monitor()\n",
    "rewards = monitor.rewards\n",
    "traces = monitor.traces\n",
    "\n",
    "trace = traces[rewards.index(max(rewards))]\n",
    "y = [t[1][0] for t in trace]\n",
    "x = range(len(y))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor = benchmark.measures[0].result[1][0].get_alg_monitor()\n",
    "rewards = monitor.rewards\n",
    "traces = monitor.traces\n",
    "\n",
    "trace = traces[rewards.index(max(rewards))]\n",
    "y = [t[1][0] for t in trace]\n",
    "x = range(len(y))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
